{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passing-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cordless-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adequate-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([transforms.Resize((224,224)), \n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "otherwise-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train': ImageFolder(root = './train', transform = image_transforms),\n",
    "        'test' : ImageFolder(root = './test', transform = image_transforms)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excited-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'with_incorrect': 0, 'with_mask': 1, 'without_mask': 2},\n",
       " {'with_incorrect': 0, 'with_mask': 1, 'without_mask': 2},\n",
       " 6126,\n",
       " 1018)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].class_to_idx, data['test'].class_to_idx, len(data['train']), len(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "likely-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': DataLoader(data['train'], batch_size = 100, shuffle = True),\n",
    "               'test' : DataLoader(data['test'], batch_size = 100, shuffle = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focal-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res18 = models.resnet18(pretrained=True)\n",
    "model_res18.fc = nn.Linear(model_res18.fc.in_features, 3)\n",
    "model_res18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "native-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_res18.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adopted-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d36314697ba49c6acd8c27b827c081a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "training_loss:  tensor(0.2816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "EPOCH 2\n",
      "training_loss:  tensor(0.1519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "EPOCH 3\n",
      "training_loss:  tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "EPOCH 4\n",
      "training_loss:  tensor(0.2453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "EPOCH 5\n",
      "training_loss:  tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    for image, label in dataloaders['train']:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        model_res18.zero_grad()\n",
    "        prediction = model_res18(image)\n",
    "        loss = criterion(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"EPOCH\", epoch)\n",
    "    print('training_loss: ', loss)\n",
    "    train_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alone-convergence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.906\n",
      "correct  922\n",
      "total 1018\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model_res18.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, label in dataloaders['test']:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        prediction = model_res18(image)\n",
    "        #loss = loss_fun(prediction, label)\n",
    "        #print(prediction)\n",
    "        for k in range(len(prediction)):\n",
    "            #print(k)\n",
    "            #print(prediction)\n",
    "            #print(label)\n",
    "            if torch.argmax(prediction[k]) == label[k]:\n",
    "                correct+=1\n",
    "                #print(image.shape)\n",
    "            total += 1\n",
    "\n",
    "#validation_loss.append(loss)    \n",
    "#print('validation_loss: ', loss)\n",
    "print('accuracy: ', round(correct/total, 3))\n",
    "print('correct ', correct)\n",
    "print('total', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.eval() is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. You need to turn off them during model evaluation, and .eval() will do it for you. In addition, the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation:\n",
    "\n",
    "# evaluate model:\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    ...\n",
    "    out_data = model(data)\n",
    "    ...\n",
    "BUT, don't forget to turn back to training mode after eval step:\n",
    "\n",
    "# training step\n",
    "...\n",
    "model.train()\n",
    "...\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
